#!/usr/bin/python3
# -*- coding: utf-8 -*-

import requests
import os
import time
from parsel import Selector
import re
import random
from bs4 import BeautifulSoup


def User_Agent(page):
    User_Agent = [
        "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.835.163 Safari/535.1",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_0) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11",
        "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0) Gecko/20100101 Firefox/6.0",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1",
        "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50",
        "Mozilla/5.0 (Windows; U; Windows NT 6.1; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50",
        "Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; en) Presto/2.8.131 Version/11.11",
        "Opera/9.80 (Windows NT 6.1; U; en) Presto/2.8.131 Version/11.11",
        "Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko",
        "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;",
        "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0)",
        "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0)",
        "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)",
        "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; GTB7.0)",
        "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)",
        "Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1)",
        "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Maxthon 2.0)",
        "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; SE 2.X MetaSr 1.0; SE 2.X MetaSr 1.0; .NET CLR 2.0.50727; SE 2.X MetaSr 1.0)",
        "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; 360SE)",
        "Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; TencentTraveler 4.0)",
    ]
    ua = random.choice(User_Agent)
    global header
    header = {"User-Agent": ua,
              'Referer': 'https://www.mzitu.com/page/{}/'.format(page),
              }


def Req(page):
    header = User_Agent(page)
    print(header)
    url_dir = 'https://www.mzitu.com/page/{}/'.format(page)
    res = requests.get(url_dir, headers=header)
    try:
        if res.status_code == 200:
            html = res.text
            return html
    except Exception as f:
        print(f)


def parse(html):
    selectors = Selector(text=html)
    selectors = selectors.xpath('//ul[@id="pins"]/li')
    # print(selectors)
    for selector in selectors:
        url = selector.xpath('./span//@href').get()
        print(url)

        resp = requests.get(url, headers=header)
        if resp.status_code == 200:
            html1 = resp.text
            # print(html1)
            print('----' * 7)
            # return html1
            content = resp.content  # 获取html
            soup = BeautifulSoup(content, 'lxml')  # 解析html
            title = soup.find('h2', class_='main-title').string  # 需要用class_
            picture_max = soup.find('div', class_='pagenavi').find_all('a')[-2].string  # 一共多少张图
            dir_name = re.findall('<h2 class="main-title">(.*?)</h2>', html1)[-1]
            if not os.path.exists(dir_name):
                os.mkdir(dir_name)

            for i in range(1, int(picture_max)):
                print('正在获取{}第{}图片'.format(title, i))
                # href = url + '/' + str(i)  # 访问每一页
                try:
                    resp = requests.get(url + '/' + str(i), headers=header)  # 请求数据
                    content = resp.content  # 得到二进制对象
                    soup = BeautifulSoup(content, 'lxml')  # 初始化
                    # 找img标签，访问src属性，找图片url
                    picture_url = soup.find('img', alt=title).attrs['src']
                    # 访问图片url
                    resp_img = requests.get(picture_url, headers=header)
                    # 获取二进制图片文件
                    content_img = resp_img.content
                    # 命名文件，注意加.jpg
                    file_name = title + '-' + str(i) + '.jpg'
                except Exception as f:
                    print(f)
                    pass
                # 写入，注意以二进制写入方式打开
                with open(dir_name + '/' + file_name, 'wb') as f:
                    f.write(content_img)
            time.sleep(3)


def main():
    for page in range(1, 10):
        html = Req(page)
        parse(html)


if __name__ == '__main__':
    main()
